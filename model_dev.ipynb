{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ec6f3bb",
   "metadata": {},
   "source": [
    "**Precision: 0.0237 Recall: 0.5204 F 1: 0.0454 ROC-AUC: 0.8439**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc6e5449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Обучение модели...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [02:01:15] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1758007651359/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 39000, number of negative: 39000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10239\n",
      "[LightGBM] [Info] Number of data points in the train set: 78000, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[02:01:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1758007651359/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[02:01:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1758007651359/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[02:01:17] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1758007651359/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 26000, number of negative: 26000\n",
      "[LightGBM] [Info] Number of positive: 26000, number of negative: 26000\n",
      "[LightGBM] [Info] Number of positive: 26000, number of negative: 26000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.016717 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10152\n",
      "[LightGBM] [Info] Number of data points in the train set: 52000, number of used features: 62\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014351 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Total Bins 10152\n",
      "[LightGBM] [Info] Number of data points in the train set: 52000, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.028055 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10159\n",
      "[LightGBM] [Info] Number of data points in the train set: 52000, number of used features: 62\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/anaconda3/envs/ml_env/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 100 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=100).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Выбран порог для максимального Recall: 0.0100\n",
      "\n",
      "=== Метрики модели на тесте ===\n",
      "Accuracy: 0.8492\n",
      "Precision: 0.0169\n",
      "Recall: 0.6735\n",
      "F1: 0.0330\n",
      "ROC-AUC: 0.8601\n",
      "\n",
      "Матрица ошибок:\n",
      "[[21698  3832]\n",
      " [   32    66]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['stacking_pipelineAccuracy: 0.8652 Precision: 0.0186 Recall: 0.6633 F1: 0.0363 ROC-AUC: 0.8661.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "\n",
    "# === Кастомный трансформер для feature selection + ресемплинга ===\n",
    "class Preprocessor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, variance_thresh=1e-5, corr_thresh=0.95, importance_thresh=0.001, undersample_ratio=100):\n",
    "        self.variance_thresh = variance_thresh\n",
    "        self.corr_thresh = corr_thresh\n",
    "        self.importance_thresh = importance_thresh\n",
    "        self.undersample_ratio = undersample_ratio\n",
    "        self.features_to_drop_ = []\n",
    "        self.smote_ = None\n",
    "        self.rf_ = None\n",
    "        self.feature_names_ = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # 1. Удаление малополезных фич\n",
    "        low_variance_features = X.columns[X.var() < self.variance_thresh].tolist()\n",
    "        corr_matrix = X.corr().abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        high_corr_features = [col for col in upper.columns if any(upper[col] > self.corr_thresh)]\n",
    "\n",
    "        self.rf_ = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "        self.rf_.fit(X, y)\n",
    "        importances = pd.Series(self.rf_.feature_importances_, index=X.columns)\n",
    "        low_importance_features = importances[importances < self.importance_thresh].index.tolist()\n",
    "\n",
    "        self.features_to_drop_ = list(set(low_variance_features + high_corr_features + low_importance_features))\n",
    "\n",
    "        # 2. Запоминаем SMOTE\n",
    "        self.smote_ = SMOTE(random_state=42)\n",
    "\n",
    "        # 3. Запоминаем порядок фич\n",
    "        self.feature_names_ = [f for f in X.columns if f not in self.features_to_drop_]\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = X.drop(columns=self.features_to_drop_, errors=\"ignore\")\n",
    "        X = X.reindex(columns=self.feature_names_, fill_value=0)\n",
    "        # Очистка имён колонок для XGBoost / LightGBM\n",
    "        X.columns = [str(c).replace(\"[\", \"_\")\n",
    "                            .replace(\"]\", \"_\")\n",
    "                            .replace(\"(\", \"_\")\n",
    "                            .replace(\")\", \"_\")\n",
    "                            .replace(\",\", \"_\")\n",
    "                            .replace(\" \", \"\")\n",
    "                            .replace(\"<\", \"lt\")\n",
    "                            .replace(\">\", \"gt\")\n",
    "                    for c in X.columns]\n",
    "        return X\n",
    "\n",
    "    def resample_fit(self, X, y):\n",
    "        # undersampling\n",
    "        X_majority = X[y == 0]\n",
    "        y_majority = y[y == 0]\n",
    "        X_minority = X[y == 1]\n",
    "        y_minority = y[y == 1]\n",
    "\n",
    "        n_majority = len(y_minority) * self.undersample_ratio\n",
    "        X_majority_down, y_majority_down = resample(\n",
    "            X_majority, y_majority, replace=False, n_samples=min(n_majority, len(y_majority)), random_state=42\n",
    "        )\n",
    "\n",
    "        X_bal = pd.concat([X_majority_down, X_minority])\n",
    "        y_bal = pd.concat([y_majority_down, y_minority])\n",
    "\n",
    "        X_res, y_res = self.smote_.fit_resample(X_bal, y_bal)\n",
    "        return X_res, y_res\n",
    "\n",
    "\n",
    "# === 1. Загрузка данных ===\n",
    "data = pd.read_csv(\"TrainDataNew.csv\", sep=\";\")\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 2. Создаём препроцессор и ресемплим ===\n",
    "prep = Preprocessor()\n",
    "prep.fit(X_train, y_train)\n",
    "X_train_res, y_train_res = prep.resample_fit(prep.transform(X_train), y_train)\n",
    "\n",
    "# === 3. Определяем модели ===\n",
    "base_models = [\n",
    "    (\"lr\", LogisticRegression(random_state=42)),\n",
    "    (\"xgb\", XGBClassifier(n_estimators=300, learning_rate=0.05, max_depth=6,\n",
    "                          subsample=0.8, colsample_bytree=0.8,\n",
    "                          eval_metric=\"logloss\", use_label_encoder=False, random_state=42)),\n",
    "    (\"lgbm\", LGBMClassifier(n_estimators=300, learning_rate=0.05,\n",
    "                            subsample=0.8, colsample_bytree=0.8, random_state=42))\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "stack_model = StackingClassifier(\n",
    "    estimators=base_models,\n",
    "    final_estimator=meta_model,\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === 4. Обучение ===\n",
    "print(\"\\nОбучение модели...\")\n",
    "stack_model.fit(X_train_res, y_train_res)\n",
    "\n",
    "\n",
    "# === 5. Подбор порога по Recall ===\n",
    "y_pred_proba = stack_model.predict_proba(prep.transform(X_test))[:, 1]\n",
    "best_threshold = 0.05\n",
    "best_recall = 0\n",
    "\n",
    "for t in np.linspace(0.01, 0.1, 10):\n",
    "    y_pred_t = (y_pred_proba >= t).astype(int)\n",
    "    r = recall_score(y_test, y_pred_t)\n",
    "    if r > best_recall:\n",
    "        best_recall = r\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"\\nВыбран порог для максимального Recall: {best_threshold:.4f}\")\n",
    "\n",
    "# === 5b. Метрики на тесте ===\n",
    "y_pred_optimal = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_test, y_pred_optimal),\n",
    "    \"Precision\": precision_score(y_test, y_pred_optimal, zero_division=0),\n",
    "    \"Recall\": recall_score(y_test, y_pred_optimal),\n",
    "    \"F1\": f1_score(y_test, y_pred_optimal),\n",
    "    \"ROC-AUC\": roc_auc_score(y_test, y_pred_proba)\n",
    "}\n",
    "\n",
    "print(\"\\n=== Метрики модели на тесте ===\")\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "print(\"\\nМатрица ошибок:\")\n",
    "print(confusion_matrix(y_test, y_pred_optimal))\n",
    "\n",
    "\n",
    "# === 6. Сохраняем пайплайн ===\n",
    "pipeline = {\n",
    "    \"preprocessor\": prep,\n",
    "    \"model\": stack_model,\n",
    "    \"threshold\": best_threshold\n",
    "}\n",
    "joblib.dump(pipeline, \"stacking_pipelineAccuracy: 0.8652 Precision: 0.0186 Recall: 0.6633 F1: 0.0363 ROC-AUC: 0.8661.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ed10d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Метрики на ваших данных ===\n",
      "Accuracy: 0.9004\n",
      "Precision: 0.0140\n",
      "Recall: 0.3627\n",
      "F1: 0.0270\n",
      "ROC-AUC: 0.7784\n",
      "\n",
      "Матрица ошибок:\n",
      "[[115203  12448]\n",
      " [   311    177]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score, accuracy_score, confusion_matrix\n",
    "\n",
    "def main():\n",
    "    # Загружаем пайплайн\n",
    "    pipeline = joblib.load(\"stacking_pipelineAccuracy: 0.8652 Precision: 0.0186 Recall: 0.6633 F1: 0.0363 ROC-AUC: 0.8661.pkl\")\n",
    "    prep = pipeline[\"preprocessor\"]\n",
    "    model = pipeline[\"model\"]\n",
    "    threshold = pipeline[\"threshold\"]\n",
    "\n",
    "    # Загружаем новые данные\n",
    "    df = pd.read_csv(\"data.csv\")\n",
    "    y_true = df[\"target\"] if \"target\" in df.columns else None\n",
    "    X = df.drop(columns=[\"target\"], errors=\"ignore\")\n",
    "\n",
    "    # Препроцессинг\n",
    "    X = prep.transform(X)\n",
    "\n",
    "    # Предсказания\n",
    "    y_pred_proba = model.predict_proba(X)[:, 1]\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "    if y_true is not None:\n",
    "        metrics = {\n",
    "            \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "            \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "            \"Recall\": recall_score(y_true, y_pred),\n",
    "            \"F1\": f1_score(y_true, y_pred),\n",
    "            \"ROC-AUC\": roc_auc_score(y_true, y_pred_proba)\n",
    "        }\n",
    "        print(\"=== Метрики на ваших данных ===\")\n",
    "        for k, v in metrics.items():\n",
    "            print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "        print(\"\\nМатрица ошибок:\")\n",
    "        print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f63f2b",
   "metadata": {},
   "source": [
    "**Precision: 0.0501, Recall: 0.3980, F1: 0.0889, ROC-AUC: 0.8640.pkl**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3959217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оставшиеся признаки: 62\n",
      "\n",
      "Распределение классов после undersampling:\n",
      "target\n",
      "0    39000\n",
      "1      390\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Распределение классов после SMOTE:\n",
      "target\n",
      "0    39000\n",
      "1    10000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Обучение модели...\n",
      "\n",
      "Выбран порог для компромисса Recall/Precision: 0.1100\n",
      "\n",
      "Метрики модели:\n",
      "Accuracy: 0.9688, Precision: 0.0501, Recall: 0.3980, F1: 0.0889, ROC-AUC: 0.8640\n",
      "\n",
      "Матрица ошибок:\n",
      "[[24790   740]\n",
      " [   59    39]]\n",
      "Модель и компоненты пайплайна сохранены в файл 'model_pipeline.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === 1. Загрузка данных ===\n",
    "data = pd.read_csv(\"TrainDataNew.csv\", sep=\";\")\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "X.columns = [f\"f{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 2. Удаляем бесполезные признаки ===\n",
    "low_var = X_train.columns[X_train.var() < 1e-5].tolist()\n",
    "corr_matrix = X_train.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "high_corr = [col for col in upper.columns if any(upper[col] > 0.95)]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "low_importance = importances[importances < 0.001].index.tolist()\n",
    "\n",
    "drop_features = list(set(low_var + high_corr + low_importance))\n",
    "X_train = X_train.drop(columns=drop_features)\n",
    "X_test = X_test.drop(columns=drop_features, errors='ignore')\n",
    "print(f\"Оставшиеся признаки: {X_train.shape[1]}\")\n",
    "\n",
    "# === 3. Undersampling класса 0 ===\n",
    "X_maj = X_train[y_train==0]\n",
    "y_maj = y_train[y_train==0]\n",
    "X_min = X_train[y_train==1]\n",
    "y_min = y_train[y_train==1]\n",
    "\n",
    "n_majority = 39000 \n",
    "X_maj_down, y_maj_down = resample(X_maj, y_maj, replace=False, n_samples=n_majority, random_state=42)\n",
    "X_bal = pd.concat([X_maj_down, X_min])\n",
    "y_bal = pd.concat([y_maj_down, y_min])\n",
    "\n",
    "print(\"\\nРаспределение классов после undersampling:\")\n",
    "print(y_bal.value_counts())\n",
    "\n",
    "# === 4. SMOTE для единичек (частично) ===\n",
    "n_minority = 10000 \n",
    "sm = SMOTE(sampling_strategy={1: n_minority}, random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_bal, y_bal)\n",
    "\n",
    "print(\"\\nРаспределение классов после SMOTE:\")\n",
    "print(pd.Series(y_res).value_counts())\n",
    "\n",
    "# === 5. Один сильный бустер: XGBoost ===\n",
    "scale_pos_weight = len(y_res[y_res==0]) / len(y_res[y_res==1])\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "\n",
    "print(\"\\nОбучение модели...\")\n",
    "model.fit(X_res, y_res)\n",
    "\n",
    "# === 6. Предсказание вероятностей ===\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# === 7. Подбор порога для компромисса Recall/Precision ===\n",
    "thresholds = np.linspace(0.01, 0.2, 20)\n",
    "best_threshold = 0.05\n",
    "best_recall = 0\n",
    "for t in thresholds:\n",
    "    y_pred = (y_pred_proba >= t).astype(int)\n",
    "    r = recall_score(y_test, y_pred)\n",
    "    p = precision_score(y_test, y_pred)\n",
    "    if r > best_recall and p >= 0.05: \n",
    "        best_recall = r\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"\\nВыбран порог для компромисса Recall/Precision: {best_threshold:.4f}\")\n",
    "y_pred_optimal = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "# === 8. Метрики ===\n",
    "acc = (y_pred_optimal == y_test).mean()\n",
    "precision = precision_score(y_test, y_pred_optimal)\n",
    "recall = recall_score(y_test, y_pred_optimal)\n",
    "f1 = f1_score(y_test, y_pred_optimal)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"\\nМетрики модели:\")\n",
    "print(f\"Accuracy: {acc:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# === 9. Матрица ошибок ===\n",
    "cm = confusion_matrix(y_test, y_pred_optimal)\n",
    "print(\"\\nМатрица ошибок:\")\n",
    "print(cm)\n",
    "\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# === 10. Сохранение модели и необходимых объектов ===\n",
    "pipeline_objects = {\n",
    "    'model': model,\n",
    "    'threshold': best_threshold,\n",
    "    'drop_features': drop_features,\n",
    "    'feature_names': X_train.columns.tolist()  \n",
    "}\n",
    "\n",
    "joblib.dump(pipeline_objects, 'model_pipeline_Precision: 0.0501, Recall: 0.3980, F1: 0.0889, ROC-AUC: 0.8640.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be90c59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Оставшиеся признаки: 62\n",
      "\n",
      "Распределение классов после undersampling:\n",
      "target\n",
      "0    39000\n",
      "1      390\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Распределение классов после SMOTE:\n",
      "target\n",
      "0    39000\n",
      "1    10000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Обучение модели...\n",
      "\n",
      "Выбран порог для компромисса Recall/Precision: 0.1100\n",
      "\n",
      "Метрики модели:\n",
      "Accuracy: 0.9688\n",
      "Precision: 0.0501\n",
      "Recall: 0.3980\n",
      "F1: 0.0889\n",
      "ROC-AUC: 0.8640\n",
      "\n",
      "Матрица ошибок:\n",
      "[[24790   740]\n",
      " [   59    39]]\n",
      "\n",
      "Модель и компоненты пайплайна сохранены в файл 'model_pipeline.pkl'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "import joblib\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# === 1. Загрузка данных ===\n",
    "data = pd.read_csv(\"TrainDataNew.csv\", sep=\";\")\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "X.columns = [f\"f{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# === 2. Удаляем малополезные признаки ===\n",
    "low_var = X_train.columns[X_train.var() < 1e-5].tolist()\n",
    "corr_matrix = X_train.corr().abs()\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "high_corr = [col for col in upper.columns if any(upper[col] > 0.95)]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "importances = pd.Series(rf.feature_importances_, index=X_train.columns)\n",
    "low_importance = importances[importances < 0.001].index.tolist()\n",
    "\n",
    "drop_features = list(set(low_var + high_corr + low_importance))\n",
    "X_train = X_train.drop(columns=drop_features)\n",
    "X_test = X_test.drop(columns=drop_features, errors='ignore')\n",
    "print(f\"Оставшиеся признаки: {X_train.shape[1]}\")\n",
    "\n",
    "# === 3. Undersampling класса 0 ===\n",
    "X_maj = X_train[y_train==0]\n",
    "y_maj = y_train[y_train==0]\n",
    "X_min = X_train[y_train==1]\n",
    "y_min = y_train[y_train==1]\n",
    "\n",
    "n_majority = len(y_min) * 100  # можно регулировать\n",
    "X_maj_down, y_maj_down = resample(X_maj, y_maj, replace=False, n_samples=min(n_majority, len(y_maj)), random_state=42)\n",
    "X_bal = pd.concat([X_maj_down, X_min])\n",
    "y_bal = pd.concat([y_maj_down, y_min])\n",
    "\n",
    "print(\"\\nРаспределение классов после undersampling:\")\n",
    "print(y_bal.value_counts())\n",
    "\n",
    "# === 4. SMOTE для единичек ===\n",
    "n_minority = 10000  # можно регулировать\n",
    "sm = SMOTE(sampling_strategy={1: n_minority}, random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X_bal, y_bal)\n",
    "\n",
    "print(\"\\nРаспределение классов после SMOTE:\")\n",
    "print(pd.Series(y_res).value_counts())\n",
    "\n",
    "# === 5. XGBoost ===\n",
    "scale_pos_weight = len(y_res[y_res==0]) / len(y_res[y_res==1])\n",
    "model = XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"logloss\",\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    scale_pos_weight=scale_pos_weight\n",
    ")\n",
    "\n",
    "print(\"\\nОбучение модели...\")\n",
    "model.fit(X_res, y_res)\n",
    "\n",
    "# === 6. Предсказание вероятностей ===\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "# === 7. Подбор порога для компромисса Recall/Precision ===\n",
    "thresholds = np.linspace(0.01, 0.2, 20)\n",
    "best_threshold = 0.05\n",
    "best_recall = 0\n",
    "for t in thresholds:\n",
    "    y_pred = (y_pred_proba >= t).astype(int)\n",
    "    r = recall_score(y_test, y_pred)\n",
    "    p = precision_score(y_test, y_pred)\n",
    "    if r > best_recall and p >= 0.05:  # отдаём приоритет Recall\n",
    "        best_recall = r\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"\\nВыбран порог для компромисса Recall/Precision: {best_threshold:.4f}\")\n",
    "y_pred_optimal = (y_pred_proba >= best_threshold).astype(int)\n",
    "\n",
    "# === 8. Метрики ===\n",
    "acc = accuracy_score(y_test, y_pred_optimal)\n",
    "precision = precision_score(y_test, y_pred_optimal)\n",
    "recall = recall_score(y_test, y_pred_optimal)\n",
    "f1 = f1_score(y_test, y_pred_optimal)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"\\nМетрики модели:\")\n",
    "print(f\"Accuracy: {acc:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1: {f1:.4f}\")\n",
    "print(f\"ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# === 9. Матрица ошибок ===\n",
    "cm = confusion_matrix(y_test, y_pred_optimal)\n",
    "print(\"\\nМатрица ошибок:\")\n",
    "print(cm)\n",
    "\n",
    "# === 10. Сохранение модели и компонентов ===\n",
    "pipeline_objects = {\n",
    "    'model': model,\n",
    "    'threshold': best_threshold,\n",
    "    'drop_features': drop_features,\n",
    "    'feature_names': X_train.columns.tolist()\n",
    "}\n",
    "\n",
    "joblib.dump(pipeline_objects, 'model_pipelinePrecision: 0.0501 Recall: 0.3980 F1: 0.0889 ROC-AUC: 0.8640.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1a775e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f0     89734\n",
       "f1     57903\n",
       "f2     72096\n",
       "f3     13053\n",
       "f4     18049\n",
       "       ...  \n",
       "f68        2\n",
       "f69        2\n",
       "f70        2\n",
       "f71        2\n",
       "f72        2\n",
       "Length: 73, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1ff01686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f53      -0.032622\n",
      "f7       -0.031325\n",
      "f24      -0.030921\n",
      "f0       -0.029216\n",
      "f19      -0.028059\n",
      "            ...   \n",
      "f4        0.035469\n",
      "f6        0.050106\n",
      "f67       0.052100\n",
      "f58       0.066235\n",
      "target    1.000000\n",
      "Name: target, Length: 74, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "corr = X.join(y).corr()['target'].sort_values()\n",
    "print(corr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6cb631",
   "metadata": {},
   "source": [
    "**Recall: 0.8367, Precision: 0.0118, F1: 0.0232, ROC-AUC: 0.8675**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7e2127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Лучшая модель ===\n",
      "Recall: 0.8367, Precision: 0.0118, F1: 0.0232, ROC-AUC: 0.8675\n",
      "Матрица ошибок:\n",
      "[[18639  6891]\n",
      " [   16    82]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_xgb_model_Recall: 0.8367, Precision: 0.0118, F1: 0.0232, ROC-AUC: 0.8675.pkl']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# === 1. Загружаем тренировочные данные ===\n",
    "\n",
    "data = pd.read_csv(\"TrainDataNew.csv\", sep=\";\")\n",
    "X = data.drop(\"target\", axis=1)\n",
    "y = data[\"target\"]\n",
    "\n",
    "X.columns = [f\"f{i}\" for i in range(X.shape[1])]\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# === 2. Сетка параметров ===\n",
    "n_majority_list = [10000, 20000, 30000, 39000]\n",
    "n_minority_list = [1000, 5000, 8000, 10000, 15000]\n",
    "threshold_list = np.linspace(0.01, 0.1, 10)\n",
    "\n",
    "best_result = {\"recall\": 0, \"precision\": 0, \"f1\": 0, \"threshold\":0,\n",
    "               \"n_majority\":0, \"n_minority\":0,\n",
    "               \"metrics\": (0,0,0,0,None),\n",
    "               \"model\": None}\n",
    "\n",
    "for n_maj in n_majority_list:\n",
    "    X_maj = X_train[y_train==0]\n",
    "    y_maj = y_train[y_train==0]\n",
    "    X_min = X_train[y_train==1]\n",
    "    y_min = y_train[y_train==1]\n",
    "\n",
    "    n_maj = min(n_maj, len(y_maj))\n",
    "    X_maj_down, y_maj_down = resample(X_maj, y_maj, replace=False, n_samples=n_maj, random_state=42)\n",
    "    X_bal = pd.concat([X_maj_down, X_min])\n",
    "    y_bal = pd.concat([y_maj_down, y_min])\n",
    "\n",
    "    for n_min in n_minority_list:\n",
    "        sm = SMOTE(sampling_strategy={1: n_min}, random_state=42)\n",
    "        X_res, y_res = sm.fit_resample(X_bal, y_bal)\n",
    "\n",
    "        scale_pos_weight = len(y_res[y_res==0]) / len(y_res[y_res==1])\n",
    "        model = XGBClassifier(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            eval_metric=\"logloss\",\n",
    "            use_label_encoder=False,\n",
    "            random_state=42,\n",
    "            scale_pos_weight=scale_pos_weight\n",
    "        )\n",
    "        model.fit(X_res, y_res)\n",
    "\n",
    "        y_pred_proba = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "        for thr in threshold_list:\n",
    "            y_pred = (y_pred_proba >= thr).astype(int)\n",
    "            r = recall_score(y_test, y_pred)\n",
    "            p = precision_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            if r > best_result[\"recall\"] and p >= 0.01:\n",
    "                best_result.update({\n",
    "                    \"recall\": r,\n",
    "                    \"precision\": p,\n",
    "                    \"f1\": f1,\n",
    "                    \"threshold\": thr,\n",
    "                    \"n_majority\": n_maj,\n",
    "                    \"n_minority\": n_min,\n",
    "                    \"metrics\": (r, p, f1, roc_auc_score(y_test, y_pred_proba), confusion_matrix(y_test, y_pred)),\n",
    "                    \"model\": model\n",
    "                })\n",
    "\n",
    "# === 3. Сохраняем лучшую модель с фичами и порогом ===\n",
    "r, p, f1, roc_auc, cm = best_result[\"metrics\"]\n",
    "print(\"\\n=== Лучшая модель ===\")\n",
    "print(f\"Recall: {r:.4f}, Precision: {p:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "print(\"Матрица ошибок:\")\n",
    "print(cm)\n",
    "\n",
    "joblib.dump({\n",
    "    \"model\": best_result[\"model\"],\n",
    "    \"features\": X_train.columns.tolist(),\n",
    "    \"threshold\": best_result[\"threshold\"],\n",
    "}, \"best_xgb_model_Recall: 0.8367, Precision: 0.0118, F1: 0.0232, ROC-AUC: 0.8675.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9484232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   f0        f1        f2     f3      f4        f5        f6   f7   f8   f9  \\\n",
      "0   1  0.198778  0.099389   0.00  799.90  1.777556  0.888778  132  0.0  1.0   \n",
      "1   2  0.043000  0.021264  49.97  173.03  0.384511  0.190143    6  0.0  0.0   \n",
      "2   3  0.067073  0.067073   0.00  329.90  0.599818  0.599818   71  0.0  0.0   \n",
      "3   4  0.052700  0.052700   0.00  235.65  0.471300  0.471300   48  0.0  0.0   \n",
      "4   5  0.141880  0.141880   0.00  634.45  1.268900  1.268900   48  0.0  0.0   \n",
      "5   6  0.054657  0.025507   0.00  171.10  0.488857  0.228133   44  0.0  0.0   \n",
      "6   7  0.117114  0.051237  40.70  366.60  1.047429  0.458250   38  1.0  0.0   \n",
      "7   8  0.088231  0.088231  57.05  512.85  0.789000  0.789000   24  1.0  0.0   \n",
      "8   9  0.079242  0.079242  26.03  233.87  0.708697  0.708697  421  0.0  0.0   \n",
      "9  10  0.080296  0.049273   0.00  223.90  0.829259  0.508864   18  1.0  0.0   \n",
      "\n",
      "   ...    f63    f64    f65    f66    f67    f68    f69    f70    f71    f72  \n",
      "0  ...  False  False  False  False  False  False  False  False   True  False  \n",
      "1  ...  False  False  False  False  False  False  False  False   True  False  \n",
      "2  ...  False  False  False  False  False  False  False  False   True  False  \n",
      "3  ...  False  False  False  False  False  False  False  False   True  False  \n",
      "4  ...  False  False  False  False  False  False  False  False   True  False  \n",
      "5  ...  False  False  False  False  False  False  False  False   True  False  \n",
      "6  ...  False  False  False  False  False  False  False  False   True  False  \n",
      "7  ...  False  False  False  False  False  False  False  False   True  False  \n",
      "8  ...  False  False  False  False  False  False  False  False   True  False  \n",
      "9  ...  False  False  False   True  False  False  False  False  False  False  \n",
      "\n",
      "[10 rows x 73 columns]\n",
      "\n",
      "=== Метрики на данных ===\n",
      "Recall: 0.9672, Precision: 0.0135, F1: 0.0267, ROC-AUC: 0.9725\n",
      "Матрица ошибок:\n",
      "[[93271 34380]\n",
      " [   16   472]]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "# === 1. Функция предобработки данных (из data_Analysis.ipynb) ===\n",
    "def preprocess_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    \n",
    "    categorical_columns = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    if 'v' in categorical_columns:\n",
    "        categorical_columns.remove('v')\n",
    "\n",
    "\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_data = encoder.fit_transform(df[categorical_columns])\n",
    "    feature_names = encoder.get_feature_names_out(categorical_columns)\n",
    "    encoded_df = pd.DataFrame(encoded_data, columns=feature_names, index=df.index)\n",
    "\n",
    "    # Удаляем последний dummy для каждой категории\n",
    "    cols_to_drop = []\n",
    "    for col in categorical_columns:\n",
    "        col_cols = [c for c in encoded_df.columns if c.startswith(f\"{col}_\")]\n",
    "        if col_cols:\n",
    "            cols_to_drop.append(col_cols[-1])\n",
    "    encoded_df = encoded_df.drop(columns=cols_to_drop)\n",
    "\n",
    "    df_encoded = pd.concat([df.drop(columns=categorical_columns), encoded_df], axis=1)\n",
    "\n",
    "    # One-hot для признака 'v'\n",
    "    encoder_v = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoded_data_v = encoder_v.fit_transform(df_encoded[['v']])\n",
    "    feature_names_v = encoder_v.get_feature_names_out(['v'])\n",
    "    df_v = pd.DataFrame(encoded_data_v, columns=feature_names_v, index=df_encoded.index)\n",
    "    df_encoded = pd.concat([df_encoded.drop(columns=['v']), df_v], axis=1)\n",
    "    if 'v_No' in df_encoded.columns:\n",
    "        df_encoded = df_encoded.drop(columns=['v_No'])\n",
    "\n",
    "    # Возраст по квантилям\n",
    "    df_encoded['age_bin'] = pd.qcut(df_encoded['age'], q=10, duplicates='drop')\n",
    "    df_encoded = df_encoded.drop(columns=['age'])\n",
    "    df_encoded = pd.get_dummies(df_encoded, columns=['age_bin'], prefix='age_q', drop_first=True)\n",
    "\n",
    "    # One-hot для 'g' и 'h'\n",
    "    df_encoded = pd.get_dummies(df_encoded, columns=['g', 'h'], drop_first=True)\n",
    "\n",
    "    # Масштабирование числовых\n",
    "    numeric_cols = ['a', 'b', 'c', 'd', 'e', 'f', 'l']\n",
    "    scaler = StandardScaler()\n",
    "    df_encoded[numeric_cols] = scaler.fit_transform(df_encoded[numeric_cols])\n",
    "    \n",
    "\n",
    "    df_encoded = df_encoded.drop(columns=\"target\",axis=1)\n",
    "    df_encoded = df_encoded.drop(columns=\"id\",axis=1)\n",
    "\n",
    "    return df_encoded\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    " \n",
    "\n",
    "    file_path = \"data.csv\"\n",
    "\n",
    "    # Загружаем модель\n",
    "    obj = joblib.load(\"best_xgb_model_Recall: 0.8367, Precision: 0.0118, F1: 0.0232, ROC-AUC: 0.8675.pkl\")\n",
    "    model = obj[\"model\"]\n",
    "    features = obj[\"features\"]\n",
    "    threshold = obj[\"threshold\"]\n",
    "\n",
    "    # Предобработка\n",
    "    df = pd.read_csv(file_path)\n",
    "    X = data.drop(\"target\", axis=1)\n",
    "    y_true = data[\"target\"]\n",
    "\n",
    "    X.columns = [f\"f{i}\" for i in range(X.shape[1])]\n",
    "\n",
    "\n",
    "    print(X.head(10))\n",
    "\n",
    "    # Выравниваем фичи под обученную модель\n",
    "    X = X.reindex(columns=features, fill_value=0)\n",
    "\n",
    "    # Предсказания\n",
    "    pos_class_index = list(model.classes_).index(1)  # где именно хранится класс \"1\"\n",
    "    y_pred_proba = model.predict_proba(X)[:, pos_class_index]\n",
    "    y_pred_proba = model.predict_proba(X.values)[:, 1]\n",
    "    y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "    if y_true is not None:\n",
    "        r = recall_score(y_true, y_pred)\n",
    "        p = precision_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        roc_auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        print(\"\\n=== Метрики на данных ===\")\n",
    "        print(f\"Recall: {r:.4f}, Precision: {p:.4f}, F1: {f1:.4f}, ROC-AUC: {roc_auc:.4f}\")\n",
    "        print(\"Матрица ошибок:\")\n",
    "        print(cm)\n",
    "    else:\n",
    "        print(\"\\nЦелевая переменная отсутствует. Выводим предсказания:\")\n",
    "        print(y_pred)\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
