# SkoringModel — README


---

## Краткое описание

Проект `SkoringModel` — это набор скриптов и ноутбуков для подготовки данных, обучения моделей скоринга и их оценки. В репозитории присутствуют исходные датасеты, ноутбуки с анализом и разработкой моделей, несколько сохранённых моделей (pickle) и скелет командного скрипта `main.py` для запуска одной из моделей.

---

## Зависимости (рекомендуемый минимум)

- Python 3.12
- pandas
- numpy
- scikit-learn
- joblib
- xgboost
- catboost
- matplotlib (для визуализаций в ноутбуках)
- jupyter / notebook

---

## Структура репозитория

```
SkoringModel/
 .git/                      # git-метаданные
data.csv                   # исходный датасет (raw-ish)
TrainDataNew.csv           # предварительно подготовленный датасет 
data_Analysis.ipynb        # ноутбук с разведывательным анализом (EDA)
model_dev.ipynb            # ноутбук с экспериментами и подбором моделей
main.py                    # skeleton скрипта для предсказаний и оценки 
catboost_info/             # артефакты catboost
best_xgb_model_Recall: 0.8367, Precision: 0.0118, F1: 0.0232, ROC-AUC: 0.8675.pkl
model_pipeline_Precision: 0.0501, Recall: 0.3980, F1: 0.0889, ROC-AUC: 0.8640.pkl
stacking_pipelineAccuracy: 0.8652 Precision: 0.0186 Recall: 0.6633 F1: 0.0363 ROC-AUC: 0.8661.pkl
README.md (этот файл)
```

**Краткое описание ключевых файлов:**

- `data.csv` — исходный табличный датасет (~128k строк, 26 колонок). Колонки: `id, a, b, c, ... , x, target`.
- `TrainDataNew.csv` — версия предназначена для подачи в модель.
- `data_Analysis.ipynb` — EDA: изучение распределений, корреляций, обработка выбросов, типы признаков.
- `model_dev.ipynb` — эксперименты: обучение моделей, подбор метрик, перебор гиперпараметров, построение пайплайнов.
- `main.py` — скрипт для загрузки сохранённой модели (pickle) и получения предсказаний.
- `*.pkl` — сохранённые артефакты моделей. Имена файлов содержат метрики (precision/recall/F1/ROC-AUC), см. раздел «Предобученные модели».

---

## Описание данных

Основной датасет `data.csv` содержит 128139 записей и следующие колонки (пример):

- `id` — идентификатор записи.
- `a`, `b`, `c`, `d`, `e`, `f`, `g`, `h` — числовые признаки.
- `sex` — пол (категориальный).
- `age` — возраст (число).
- `region` — регион (категориальный).
- `l`, `job_title`, `education`, `marriage`, `children`, `property`, `r`, `employment_status` — категориальные признаки о социодемографии и собственности.
- `t`, `u`, `v`, `w`, `x` — бинарные/мультикатегориальные флаги (Yes/No/Few и т.д.).
- `target` — целевая переменная (0/1), задача: бинарная классификация (скоринг).

---

## Предобученные модели (файлы .pkl)

В корне лежат три файла `.pkl`. Их имена содержат ключевые метрики, по ним можно быстро оценить приоритет использования:

- `best_xgb_model_Recall: 0.8367, Precision: 0.0118, F1: 0.0232, ROC-AUC: 0.8675.pkl` — XGBoost модель, оптимизированная под Recall.
- `model_pipeline_Precision: 0.0501, Recall: 0.3980, F1: 0.0889, ROC-AUC: 0.8640.pkl` — пайплайн, ориентированный на Precision.
- `stacking_pipelineAccuracy: 0.8652 Precision: 0.0186 Recall: 0.6633 F1: 0.0363 ROC-AUC: 0.8661.pkl` — стекинг-пайплайн нескольких моделей.

---

## Воспроизведение обучения

1. Откройте `model_dev.ipynb`.
2. Убедитесь, что у вас те же версии библиотек (xgboost/catboost/sklearn).
3. При необходимости уменьшите объём данных или параметров для быстрой отладки.
4. Сохраняйте артефакты (модели, списки признаков, энкодеры) в единый словарь и `joblib.dump(obj, 'best_model.pkl')`.